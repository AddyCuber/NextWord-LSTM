{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30918,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-03-03T05:53:06.744200Z","iopub.execute_input":"2025-03-03T05:53:06.744527Z","iopub.status.idle":"2025-03-03T05:53:07.963691Z","shell.execute_reply.started":"2025-03-03T05:53:06.744499Z","shell.execute_reply":"2025-03-03T05:53:07.962647Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import nltk\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences   \nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential, load_model\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\nimport pickle","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T05:53:10.684343Z","iopub.execute_input":"2025-03-03T05:53:10.684872Z","iopub.status.idle":"2025-03-03T05:53:28.316947Z","shell.execute_reply.started":"2025-03-03T05:53:10.684836Z","shell.execute_reply":"2025-03-03T05:53:28.315680Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"nltk.download('gutenberg')\nfrom nltk.corpus import gutenberg\n\n# Load Hamlet text\ndata = gutenberg.raw('shakespeare-hamlet.txt')\n\n# Save to a text file\nwith open('hamlet.txt', 'w') as file:\n    file.write(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T05:53:31.340086Z","iopub.execute_input":"2025-03-03T05:53:31.340772Z","iopub.status.idle":"2025-03-03T05:54:03.376706Z","shell.execute_reply.started":"2025-03-03T05:53:31.340713Z","shell.execute_reply":"2025-03-03T05:54:03.375649Z"}},"outputs":[{"name":"stdout","text":"[nltk_data] Error loading gutenberg: <urlopen error [Errno -3]\n[nltk_data]     Temporary failure in name resolution>\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"# Read the text\nwith open('hamlet.txt', 'r') as file:\n    text = file.read().lower()\n\n# Tokenize\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts([text])\n\ntotalWords = len(tokenizer.word_index) + 1  # Vocabulary size\nprint(f\"Total Vocabulary Size: {totalWords}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T05:54:06.068022Z","iopub.execute_input":"2025-03-03T05:54:06.068340Z","iopub.status.idle":"2025-03-03T05:54:06.099127Z","shell.execute_reply.started":"2025-03-03T05:54:06.068315Z","shell.execute_reply":"2025-03-03T05:54:06.098027Z"}},"outputs":[{"name":"stdout","text":"Total Vocabulary Size: 4818\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"input_sequences = []\nfor line in text.split('\\n'):  # Fixed line split\n    token_list = tokenizer.texts_to_sequences([line])[0]\n    for i in range(1, len(token_list)):\n        n_gram_sequence = token_list[:i + 1]\n        input_sequences.append(n_gram_sequence)\n\n# Pad sequences\nmax_sequence_len = max(len(x) for x in input_sequences)\ninput_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n\nprint(f\"Max Sequence Length: {max_sequence_len}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T05:54:21.762195Z","iopub.execute_input":"2025-03-03T05:54:21.762545Z","iopub.status.idle":"2025-03-03T05:54:22.125421Z","shell.execute_reply.started":"2025-03-03T05:54:21.762514Z","shell.execute_reply":"2025-03-03T05:54:22.124352Z"}},"outputs":[{"name":"stdout","text":"Max Sequence Length: 14\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"x, y = input_sequences[:, :-1], input_sequences[:, -1]\ny = tf.keras.utils.to_categorical(y, num_classes=totalWords)\n\n# Split into train and test\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T05:54:31.025479Z","iopub.execute_input":"2025-03-03T05:54:31.025869Z","iopub.status.idle":"2025-03-03T05:54:31.938374Z","shell.execute_reply.started":"2025-03-03T05:54:31.025835Z","shell.execute_reply":"2025-03-03T05:54:31.937240Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"model = Sequential([\n    Embedding(totalWords, 100, input_length=max_sequence_len - 1),\n    LSTM(100, return_sequences=True),  # Reduced units\n    Dropout(0.2),\n    LSTM(50),  # Reduced from 100 to 50\n    Dense(totalWords, activation=\"softmax\")\n])\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\nmodel.summary()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T05:54:39.630295Z","iopub.execute_input":"2025-03-03T05:54:39.630642Z","iopub.status.idle":"2025-03-03T05:54:39.712479Z","shell.execute_reply.started":"2025-03-03T05:54:39.630613Z","shell.execute_reply":"2025-03-03T05:54:39.711426Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"\u001b[1mModel: \"sequential\"\u001b[0m\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                          │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ ?                           │     \u001b[38;5;34m0\u001b[0m (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                          │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ ?                           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n","text/html":"<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"history = model.fit(x_train, y_train, epochs=50, validation_data=(x_test, y_test), verbose=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T05:54:47.457427Z","iopub.execute_input":"2025-03-03T05:54:47.457801Z","iopub.status.idle":"2025-03-03T06:08:50.578890Z","shell.execute_reply.started":"2025-03-03T05:54:47.457771Z","shell.execute_reply":"2025-03-03T06:08:50.577800Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.0326 - loss: 7.2034 - val_accuracy: 0.0326 - val_loss: 6.7141\nEpoch 2/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.0373 - loss: 6.4956 - val_accuracy: 0.0414 - val_loss: 6.7958\nEpoch 3/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.0421 - loss: 6.3481 - val_accuracy: 0.0478 - val_loss: 6.8524\nEpoch 4/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - accuracy: 0.0526 - loss: 6.2171 - val_accuracy: 0.0439 - val_loss: 6.9003\nEpoch 5/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.0471 - loss: 6.1428 - val_accuracy: 0.0495 - val_loss: 6.9071\nEpoch 6/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.0548 - loss: 6.0231 - val_accuracy: 0.0497 - val_loss: 6.9332\nEpoch 7/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.0555 - loss: 5.9684 - val_accuracy: 0.0503 - val_loss: 6.9855\nEpoch 8/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.0634 - loss: 5.8481 - val_accuracy: 0.0598 - val_loss: 7.0324\nEpoch 9/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.0686 - loss: 5.7612 - val_accuracy: 0.0645 - val_loss: 7.0693\nEpoch 10/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.0781 - loss: 5.6356 - val_accuracy: 0.0655 - val_loss: 7.1398\nEpoch 11/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.0865 - loss: 5.5105 - val_accuracy: 0.0645 - val_loss: 7.2046\nEpoch 12/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.0940 - loss: 5.4451 - val_accuracy: 0.0676 - val_loss: 7.2731\nEpoch 13/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.0967 - loss: 5.3577 - val_accuracy: 0.0676 - val_loss: 7.3435\nEpoch 14/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.1011 - loss: 5.2601 - val_accuracy: 0.0670 - val_loss: 7.4292\nEpoch 15/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.1077 - loss: 5.1925 - val_accuracy: 0.0668 - val_loss: 7.5305\nEpoch 16/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.1084 - loss: 5.0812 - val_accuracy: 0.0657 - val_loss: 7.6214\nEpoch 17/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.1141 - loss: 5.0163 - val_accuracy: 0.0666 - val_loss: 7.7089\nEpoch 18/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.1172 - loss: 4.9284 - val_accuracy: 0.0639 - val_loss: 7.7978\nEpoch 19/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 23ms/step - accuracy: 0.1205 - loss: 4.8409 - val_accuracy: 0.0635 - val_loss: 7.8974\nEpoch 20/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 22ms/step - accuracy: 0.1218 - loss: 4.8005 - val_accuracy: 0.0661 - val_loss: 7.9745\nEpoch 21/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.1293 - loss: 4.7040 - val_accuracy: 0.0641 - val_loss: 8.0684\nEpoch 22/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.1318 - loss: 4.6522 - val_accuracy: 0.0624 - val_loss: 8.1701\nEpoch 23/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.1354 - loss: 4.5991 - val_accuracy: 0.0633 - val_loss: 8.2586\nEpoch 24/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.1407 - loss: 4.5209 - val_accuracy: 0.0626 - val_loss: 8.3496\nEpoch 25/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.1471 - loss: 4.4811 - val_accuracy: 0.0631 - val_loss: 8.4251\nEpoch 26/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 29ms/step - accuracy: 0.1540 - loss: 4.3949 - val_accuracy: 0.0622 - val_loss: 8.5288\nEpoch 27/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.1626 - loss: 4.3232 - val_accuracy: 0.0657 - val_loss: 8.6114\nEpoch 28/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.1688 - loss: 4.2808 - val_accuracy: 0.0641 - val_loss: 8.7001\nEpoch 29/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 31ms/step - accuracy: 0.1759 - loss: 4.2165 - val_accuracy: 0.0641 - val_loss: 8.8067\nEpoch 30/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 33ms/step - accuracy: 0.1834 - loss: 4.1590 - val_accuracy: 0.0655 - val_loss: 8.8968\nEpoch 31/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 34ms/step - accuracy: 0.1944 - loss: 4.1103 - val_accuracy: 0.0620 - val_loss: 8.9552\nEpoch 32/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 31ms/step - accuracy: 0.1974 - loss: 4.0515 - val_accuracy: 0.0602 - val_loss: 9.0493\nEpoch 33/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.2112 - loss: 3.9890 - val_accuracy: 0.0585 - val_loss: 9.1192\nEpoch 34/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.2108 - loss: 3.9754 - val_accuracy: 0.0589 - val_loss: 9.2220\nEpoch 35/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - accuracy: 0.2202 - loss: 3.9220 - val_accuracy: 0.0546 - val_loss: 9.2919\nEpoch 36/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.2284 - loss: 3.8596 - val_accuracy: 0.0598 - val_loss: 9.3619\nEpoch 37/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.2392 - loss: 3.8065 - val_accuracy: 0.0616 - val_loss: 9.4248\nEpoch 38/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.2492 - loss: 3.7442 - val_accuracy: 0.0575 - val_loss: 9.5011\nEpoch 39/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.2545 - loss: 3.7099 - val_accuracy: 0.0593 - val_loss: 9.5578\nEpoch 40/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.2640 - loss: 3.6621 - val_accuracy: 0.0622 - val_loss: 9.6470\nEpoch 41/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.2640 - loss: 3.6217 - val_accuracy: 0.0616 - val_loss: 9.7025\nEpoch 42/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.2779 - loss: 3.5799 - val_accuracy: 0.0583 - val_loss: 9.7655\nEpoch 43/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - accuracy: 0.2852 - loss: 3.5330 - val_accuracy: 0.0600 - val_loss: 9.8287\nEpoch 44/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 24ms/step - accuracy: 0.2914 - loss: 3.4933 - val_accuracy: 0.0583 - val_loss: 9.8769\nEpoch 45/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.2929 - loss: 3.4638 - val_accuracy: 0.0587 - val_loss: 9.9532\nEpoch 46/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.3036 - loss: 3.4186 - val_accuracy: 0.0589 - val_loss: 9.9984\nEpoch 47/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.3155 - loss: 3.3602 - val_accuracy: 0.0575 - val_loss: 10.0597\nEpoch 48/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 25ms/step - accuracy: 0.3222 - loss: 3.3246 - val_accuracy: 0.0596 - val_loss: 10.1409\nEpoch 49/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 24ms/step - accuracy: 0.3231 - loss: 3.3225 - val_accuracy: 0.0596 - val_loss: 10.1542\nEpoch 50/50\n\u001b[1m644/644\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.3260 - loss: 3.2702 - val_accuracy: 0.0583 - val_loss: 10.2315\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"model.save(\"hamlet_lstm_model.h5\")\n\n# Save tokenizer\nwith open('tokenizer.pkl', 'wb') as f:\n    pickle.dump(tokenizer, f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T06:11:18.131422Z","iopub.execute_input":"2025-03-03T06:11:18.131827Z","iopub.status.idle":"2025-03-03T06:11:18.209810Z","shell.execute_reply.started":"2025-03-03T06:11:18.131795Z","shell.execute_reply":"2025-03-03T06:11:18.208581Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"# Load the model\nmodel = load_model(\"hamlet_lstm_model.h5\")\n\n# Load tokenizer\nwith open('tokenizer.pkl', 'rb') as f:\n    tokenizer = pickle.load(f)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T06:11:24.179438Z","iopub.execute_input":"2025-03-03T06:11:24.179824Z","iopub.status.idle":"2025-03-03T06:11:24.360777Z","shell.execute_reply.started":"2025-03-03T06:11:24.179792Z","shell.execute_reply":"2025-03-03T06:11:24.359219Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"def predict_next_word(model, tokenizer, text, max_sequence_len):\n    token_list = tokenizer.texts_to_sequences([text])[0]\n    token_list = token_list[-(max_sequence_len-1):]  # Ensure correct length\n    token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n    \n    predicted = model.predict(token_list, verbose=0)\n    predicted_word_index = np.argmax(predicted, axis=1)\n    \n    for word, index in tokenizer.word_index.items():\n        if index == predicted_word_index[0]:  \n            return word\n    return None","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-03T06:11:29.882310Z","iopub.execute_input":"2025-03-03T06:11:29.882672Z","iopub.status.idle":"2025-03-03T06:11:29.889330Z","shell.execute_reply.started":"2025-03-03T06:11:29.882643Z","shell.execute_reply":"2025-03-03T06:11:29.887997Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"input_text = \"To be or not to be\"\nprint(f\"Input text: {input_text}\")\n\nmax_sequence_len = model.input_shape[1] + 1\nnext_word = predict_next_word(model, tokenizer, input_text, max_sequence_len)\n\nprint(f\"The next word is: {next_word}\")","metadata":{"trusted":true,"execution":{"execution_failed":"2025-03-03T08:53:39.201Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}